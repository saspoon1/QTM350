{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS ML APIs\n",
    "In this notebook, we walk you through setting up and using an AWS machine learning API via Sagemaker. The material in this notebook largely follows the [AWS Developer Guide](https://docs.aws.amazon.com/machine-learning/?id=docs_gateway) for each service while providing details which are specific to using them in an AWS Educate account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is machine learning?\n",
    "In QTM 220, you learned how to use linear models and their variants. The focus in that class was on the statistics of the models and their estimation. Another aspect of these models is their use for making predictions, a.k.a. inferences on new data. This is typically the focus of machine learning in practice, and linear models are one of the simplest and oldest machine learning models in use. In recent years, new models that are more complex than linear modesl have come to the forefront of machine learning practice as they can provide useful inferences when dealing with fundamental problems.\n",
    "\n",
    "The text in this subsection are selections from the [Amazon Machine Learning Developer Guide](https://docs.aws.amazon.com/machine-learning/latest/dg/machine-learning-problems-in-amazon-machine-learning.html) Caution: some of the services referenced in that particular guide are no longer available (e.g. Amazon ML). Hence, we present in this section a summary that is tailored to the background of  QTM 350 students.\n",
    "\n",
    "## Examples of contemporary business problems that ML is commonly used for\n",
    "\n",
    "Examples of binary classification problems:\n",
    "\n",
    "* Is this email spam or not spam? (e.g. Gmail spam filter)\n",
    "\n",
    "* Is this tweet written by a person or a robot? (E.g. Twitter [bot or not](https://blog.twitter.com/en_us/topics/company/2020/bot-or-not.html))\n",
    "\n",
    "Examples of multiclass classification problems:\n",
    "\n",
    "* Will this user want to watch a romantic comedy, documentary, or thriller? (E.g. Netflix [Recommendation algorithms](https://research.netflix.com/research-area/recommendations))\n",
    "\n",
    "* Which category of products is most interesting to this customer? (E.g. every online shopping site)\n",
    "\n",
    "Examples of regression classification problems:\n",
    "\n",
    "* How many days before this customer stops using the application? \n",
    "\n",
    "* What price will this house sell for? (e.g. Zillow [Zestimate](https://www.zillow.com/how-much-is-my-home-worth/))\n",
    "\n",
    "## When to use machine learning?\n",
    "It is important to remember that ML is not a solution for every type of problem. For example, you don’t need ML if you can determine a target value by using simple rules, computations, or predetermined steps that can be programmed without needing any data-driven learning.\n",
    "\n",
    "### Use machine learning for the following situations:\n",
    "\n",
    "#### You cannot code the rules\n",
    "Many human tasks (such as recognizing whether an email is spam or not spam) cannot be adequately solved using a simple (deterministic), rule-based solution. A large number of factors could influence the answer. When rules depend on too many factors and many of these rules overlap or need to be tuned very finely, it soon becomes difficult for a human to accurately code the rules. You can use ML to effectively solve this problem. \n",
    "\n",
    "#### You cannot scale\n",
    "You might be able to manually recognize a few hundred emails and decide whether they are spam or not. However, this task becomes tedious for millions of emails. ML solutions are effective at handling large-scale problems.\n",
    "\n",
    "### AI vrs ML\n",
    "Oftentimes simple rules or algorithms will be called AI, however they are not ML. See the section titled \"Process automation\" in this article [Harvard Business Review article](https://hbr.org/2018/01/artificial-intelligence-for-the-real-world). There, one of the tasks they list as being solved by AI is \"transferring data from e-mail and call center systems into systems of record—for example, updating customer files with address changes or service additions\". This requires programmatic control of data (for example by architecting a solution in the cloud to solve this task), not machine learning.\n",
    "\n",
    "In the same section we find, “reading” legal and contractual documents to extract provisions using natural language processing (NLP). This is ML. Indeed, NLP tasks cannot be solved with simple algorithms or programs and require the latest machine learning models.\n",
    "\n",
    "Talk to Jinho Choi at Emory if you are interested in NLP, as he is the faculty expert on campus and his team is the recent winner of the ultimate prize in this area, the [Alexa prize](https://developer.amazon.com/alexaprize)!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Rekognition\n",
    "We first look at a machine learning tool for image and video analysis. From the [documentation](https://docs.aws.amazon.com/rekognition/latest/dg/what-is.html) you will find that:\n",
    "> Amazon Rekognition is based on the same proven, highly scalable, deep learning technology developed by Amazon’s computer vision scientists to analyze billions of images and videos daily. It requires no machine learning expertise to use.\n",
    "\n",
    "Great! Let's get started.\n",
    "\n",
    "### Set up an IAM Role\n",
    "In order to use this API within Sagemaker, we will need to update the Role we have been using to control Sagemaker permissions. Recall, when you created your Sagemaker instance, one of the steps was creating a new IAM Role. If you used the suggested default, the name would be similar to AmazonSageMaker-ExecutionRole-0238127377.\n",
    "\n",
    "#### Where can I find that role?\n",
    "Go to your Sagemaker dashboard, then notebook instances, then click the notebook instance name to access the page for the \"Notebook instance settings\". You should then see the page below.\n",
    "\n",
    "![Notebook instance settings](./screenshot-instance-settings.png)\n",
    "\n",
    "\n",
    "There, under the heading \"Permissions and encryption\" click the link to the IAM role ARN. You should then see a view similar to this one below.\n",
    "\n",
    "\n",
    "![Notebook instance settings](./sagemaker-role.png)\n",
    "\n",
    "However, your view will have fewer policies, because I have already completed the step that you are about to complete, namely, adding policies to this Sagemaker role.\n",
    "\n",
    "#### Adding policies\n",
    "As we work with new AWS services within our notebooks, it will be necessary to add policies which give Sagemaker access to them. To use the examples we will present for working with Amazon Rekognition, you will need to add `AmazonRekognitionFullAccess` permissions. Also, `AmazonS3ReadOnlyAccess` is required for examples that access images or videos that are stored in an Amazon S3 bucket. Finally, the Amazon Rekognition Video stored video code examples also require `AmazonSQSFullAccess` permissions. \n",
    "\n",
    "To add them, in the IAM role Summary page (pictured in the last screenshot), click the blue \"Attach policies\" button. In the search bar, type the names of these services that were just listed, select them by ticking the empty white box next to the name when it appears, and then click the blue \"Attach policy\" button. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting started using the console\n",
    "Before using the Rekognition service programatically, it will be helpful to understand what it does by walking through examples in the AWS console. To do that, complete Exercises 1 through 4 listed [here](https://docs.aws.amazon.com/rekognition/latest/dg/getting-started-console.html), then return to this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with the Rekognition API programatically\n",
    "In this section, you use the Amazon Rekognition Image API operations to analyze images stored in an Amazon S3 bucket.\n",
    "\n",
    "#### Step 1\n",
    "Create a new S3 bucket. This can be done graphically via the AWS console, or programaticaly using bash or the Python SDK.\n",
    "\n",
    "### Set up the AWS CLI\n",
    "In any new Sagemaker instance, the AWS CLI (Command Line Interface) comes preinstalled. Indeed, to check that this is the case, run the command below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3()                                                                      S3()\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1mNAME\u001b[0m\n",
      "       s3 -\n",
      "\n",
      "\u001b[1mDESCRIPTION\u001b[0m\n",
      "       This  section  explains  prominent concepts and notations in the set of\n",
      "       high-level S3 commands provided.\n",
      "\n",
      "       If you are looking for the low level S3 commands for  the  CLI,  please\n",
      "       see the \u001b[1ms3api \u001b[22mcommand \u001b[4mreference\u001b[24m \u001b[4mpage\u001b[24m.\n",
      "\n",
      "   \u001b[1mPath Argument Type\u001b[0m\n",
      "       Whenever using a command, at least one path argument must be specified.\n",
      "       There are two types of path arguments: \u001b[1mLocalPath \u001b[22mand \u001b[1mS3Uri\u001b[22m.\n",
      "\n",
      "       \u001b[1mLocalPath\u001b[22m: represents the path of a local file or directory.  It can be\n",
      "       written as an absolute path or relative path.\n",
      "\n",
      "       \u001b[1mS3Uri\u001b[22m: represents the location of a S3 object, prefix, or bucket.  This\n",
      "       must be written in the form \u001b[1ms3://mybucket/mykey \u001b[22mwhere \u001b[1mmybucket  \u001b[22mis  the\n",
      "       specified  S3 bucket, \u001b[1mmykey \u001b[22mis the specified S3 key.  The path argument\n",
      "       must begin with \u001b[1ms3:// \u001b[22min order to denote that the path argument  refers\n",
      "       to  a  S3  object. Note that prefixes are separated by forward slashes.\n",
      "       For example, if the S3 object \u001b[1mmyobject \u001b[22mhad the prefix \u001b[1mmyprefix\u001b[22m, the  S3\n",
      "       key  would  be  \u001b[1mmyprefix/myobject\u001b[22m,  and if the object was in the bucket\n",
      "       \u001b[1mmybucket\u001b[22m, the \u001b[1mS3Uri \u001b[22mwould be \u001b[1ms3://mybucket/myprefix/myobject\u001b[22m.\n",
      "\n",
      "       \u001b[1mS3Uri \u001b[22malso supports S3 access points. To specify an access point,  this\n",
      "       value must be of the form \u001b[1ms3://<access-point-arn>/<key>\u001b[22m. For example if\n",
      "       the  access   point   \u001b[1mmyaccesspoint   \u001b[22mto   be   used   has   the   ARN:\n",
      "       \u001b[1marn:aws:s3:us-west-2:123456789012:accesspoint/myaccesspoint   \u001b[22mand   the\n",
      "       object being accessed has the key \u001b[1mmykey\u001b[22m, then the \u001b[1mS3URI \u001b[22mused  must  be:\n",
      "       \u001b[1ms3://arn:aws:s3:us-west-2:123456789012:accesspoint/myaccesspoint/mykey\u001b[22m.\n",
      "       Similar to bucket names, you can also use prefixes  with  access  point\n",
      "       ARNs         for         the         \u001b[1mS3Uri\u001b[22m.         For        example:\n",
      "       \u001b[1ms3://arn:aws:s3:us-west-2:123456789012:accesspoint/myaccesspoint/mypre-\u001b[0m\n",
      "       \u001b[1mfix/\u001b[0m\n",
      "\n",
      "       The  higher  level \u001b[1ms3 \u001b[22mcommands do \u001b[1mnot \u001b[22msupport access point object ARNs.\n",
      "       For     example,     if     the      following      was      specified:\n",
      "       \u001b[1ms3://arn:aws:s3:us-west-2:123456789012:accesspoint/myaccess-\u001b[0m\n",
      "       \u001b[1mpoint/object/mykey  \u001b[22mthe  \u001b[1mS3URI  \u001b[22mwill  resolve   to   the   object   key\n",
      "       \u001b[1mobject/mykey\u001b[0m\n",
      "\n",
      "   \u001b[1mOrder of Path Arguments\u001b[0m\n",
      "       Every  command  takes  one or two positional path arguments.  The first\n",
      "       path argument represents the source, which is the local  file/directory\n",
      "       or  S3  object/prefix/bucket  that  is being referenced.  If there is a\n",
      "       second path argument, it represents the destination, which is the local\n",
      "       file/directory  or  S3  object/prefix/bucket that is being operated on.\n",
      "       Commands with only one path argument do not have a destination  because\n",
      "       the operation is being performed only on the source.\n",
      "\n",
      "   \u001b[1mSingle Local File and S3 Object Operations\u001b[0m\n",
      "       Some  commands  perform operations only on single files and S3 objects.\n",
      "       The following commands are single file/object operations if no \u001b[1m--recur-\u001b[0m\n",
      "       \u001b[1msive \u001b[22mflag is provided.\n",
      "\n",
      "          o \u001b[1mcp\u001b[0m\n",
      "\n",
      "          o \u001b[1mmv\u001b[0m\n",
      "\n",
      "          o \u001b[1mrm\u001b[0m\n",
      "\n",
      "       For  this  type of operation, the first path argument, the source, must\n",
      "       exist and be a local file or S3 object.  The second path argument,  the\n",
      "       destination,  can  be  the  name  of  a local file, local directory, S3\n",
      "       object, S3 prefix, or S3 bucket.\n",
      "\n",
      "       The destination is indicated as a local directory,  S3  prefix,  or  S3\n",
      "       bucket if it ends with a forward slash or back slash.  The use of slash\n",
      "       depends on the path argument type.  If the path argument  is  a  \u001b[1mLocal-\u001b[0m\n",
      "       \u001b[1mPath\u001b[22m,  the type of slash is the separator used by the operating system.\n",
      "       If the path is a \u001b[1mS3Uri\u001b[22m, the forward slash must always be  used.   If  a\n",
      "       slash  is at the end of the destination, the destination file or object\n",
      "       will adopt the name of the source file or object.  Otherwise, if  there\n",
      "       is no slash at the end, the file or object will be saved under the name\n",
      "       provided.  See examples in \u001b[1mcp \u001b[22mand \u001b[1mmv \u001b[22mto illustrate this description.\n",
      "\n",
      "   \u001b[1mDirectory and S3 Prefix Operations\u001b[0m\n",
      "       Some commands only perform operations on the contents of a local direc-\n",
      "       tory  or  S3 prefix/bucket.  Adding or omitting a forward slash or back\n",
      "       slash to the end of any path argument, depending on its type, does  not\n",
      "       affect  the  results  of  the  operation.   The following commands will\n",
      "       always result in a directory or S3 prefix/bucket operation:\n",
      "\n",
      "       o \u001b[1msync\u001b[0m\n",
      "\n",
      "       o \u001b[1mmb\u001b[0m\n",
      "\n",
      "       o \u001b[1mrb\u001b[0m\n",
      "\n",
      "       o \u001b[1mls\u001b[0m\n",
      "\n",
      "   \u001b[1mUse of Exclude and Include Filters\u001b[0m\n",
      "       Currently, there is no support for the use of UNIX style wildcards in a\n",
      "       command's  path  arguments.   However,  most  commands  have  \u001b[1m--exclude\u001b[0m\n",
      "       \u001b[1m\"<value>\" \u001b[22mand \u001b[1m--include  \"<value>\"  \u001b[22mparameters  that  can  achieve  the\n",
      "       desired  result.   These  parameters perform pattern matching to either\n",
      "       exclude or include a particular file or object.  The following  pattern\n",
      "       symbols are supported.\n",
      "\n",
      "          o \u001b[1m*\u001b[22m: Matches everything\n",
      "\n",
      "          o \u001b[1m?\u001b[22m: Matches any single character\n",
      "\n",
      "          o \u001b[1m[sequence]\u001b[22m: Matches any character in \u001b[1msequence\u001b[0m\n",
      "\n",
      "          o \u001b[1m[!sequence]\u001b[22m: Matches any character not in \u001b[1msequence\u001b[0m\n",
      "\n",
      "       Any  number of these parameters can be passed to a command.  You can do\n",
      "       this by providing an \u001b[1m--exclude \u001b[22mor \u001b[1m--include  \u001b[22margument  multiple  times,\n",
      "       e.g.   \u001b[1m--include  \"*.txt\"  --include  \"*.png\"\u001b[22m.  When there are multiple\n",
      "       filters, the rule is the filters that appear later in the command  take\n",
      "       precedence  over filters that appear earlier in the command.  For exam-\n",
      "       ple, if the filter parameters passed to the command were\n",
      "\n",
      "          --exclude \"*\" --include \"*.txt\"\n",
      "\n",
      "       All files will be excluded from the command  except  for  files  ending\n",
      "       with  \u001b[1m.txt   \u001b[22mHowever, if the order of the filter parameters was changed\n",
      "       to\n",
      "\n",
      "          --include \"*.txt\" --exclude \"*\"\n",
      "\n",
      "       All files will be excluded from the command.\n",
      "\n",
      "       Each filter is evaluated against the \u001b[1msource directory\u001b[22m.  If  the  source\n",
      "       location is a file instead of a directory, the directory containing the\n",
      "       file is used as the source directory.  For example, suppose you had the\n",
      "       following directory structure:\n",
      "\n",
      "          /tmp/foo/\n",
      "            .git/\n",
      "            |---config\n",
      "            |---description\n",
      "            foo.txt\n",
      "            bar.txt\n",
      "            baz.jpg\n",
      "\n",
      "       In  the  command \u001b[1maws s3 sync /tmp/foo s3://bucket/ \u001b[22mthe source directory\n",
      "       is \u001b[1m/tmp/foo\u001b[22m.  Any include/exclude filters will be  evaluated  with  the\n",
      "       source  directory prepended.  Below are several examples to demonstrate\n",
      "       this.\n",
      "\n",
      "       Given the directory structure above and the command \u001b[1maws s3 cp  /tmp/foo\u001b[0m\n",
      "       \u001b[1ms3://bucket/  --recursive --exclude \".git/*\"\u001b[22m, the files \u001b[1m.git/config \u001b[22mand\n",
      "       \u001b[1m.git/description \u001b[22mwill be excluded from the files to upload because  the\n",
      "       exclude  filter  \u001b[1m.git/*  \u001b[22mwill  have the source prepended to the filter.\n",
      "       This means that:\n",
      "\n",
      "          /tmp/foo/.git/* -> /tmp/foo/.git/config       (matches, should exclude)\n",
      "          /tmp/foo/.git/* -> /tmp/foo/.git/description  (matches, should exclude)\n",
      "          /tmp/foo/.git/* -> /tmp/foo/foo.txt  (does not match, should include)\n",
      "          /tmp/foo/.git/* -> /tmp/foo/bar.txt  (does not match, should include)\n",
      "          /tmp/foo/.git/* -> /tmp/foo/baz.jpg  (does not match, should include)\n",
      "\n",
      "       The command \u001b[1maws s3  cp  /tmp/foo/  s3://bucket/  --recursive  --exclude\u001b[0m\n",
      "       \u001b[1m\"ba*\" \u001b[22mwill exclude \u001b[1m/tmp/foo/bar.txt \u001b[22mand \u001b[1m/tmp/foo/baz.jpg\u001b[22m:\n",
      "\n",
      "          /tmp/foo/ba* -> /tmp/foo/.git/config      (does not match, should include)\n",
      "          /tmp/foo/ba* -> /tmp/foo/.git/description (does not match, should include)\n",
      "          /tmp/foo/ba* -> /tmp/foo/foo.txt          (does not match, should include)\n",
      "          /tmp/foo/ba* -> /tmp/foo/bar.txt  (matches, should exclude)\n",
      "          /tmp/foo/ba* -> /tmp/foo/baz.jpg  (matches, should exclude)\n",
      "\n",
      "       Note that, by default, \u001b[4mall\u001b[24m \u001b[4mfiles\u001b[24m \u001b[4mare\u001b[24m \u001b[4mincluded\u001b[24m.  This means that provid-\n",
      "       ing \u001b[1monly \u001b[22man \u001b[1m--include \u001b[22mfilter will not  change  what  files  are  trans-\n",
      "       ferred.   \u001b[1m--include  \u001b[22mwill only re-include files that have been excluded\n",
      "       from an \u001b[1m--exclude \u001b[22mfilter.  If you only want to upload files with a par-\n",
      "       ticular extension, you need to first exclude all files, then re-include\n",
      "       the files with the particular extension.  This command will upload \u001b[1monly\u001b[0m\n",
      "       files ending with \u001b[1m.jpg\u001b[22m:\n",
      "\n",
      "          aws s3 cp /tmp/foo/ s3://bucket/ --recursive --exclude \"*\" --include \"*.jpg\"\n",
      "\n",
      "       If  you wanted to include both \u001b[1m.jpg \u001b[22mfiles as well as \u001b[1m.txt \u001b[22mfiles you can\n",
      "       run:\n",
      "\n",
      "          aws s3 cp /tmp/foo/ s3://bucket/ --recursive \\\n",
      "              --exclude \"*\" --include \"*.jpg\" --include \"*.txt\"\n",
      "\n",
      "\u001b[1mSYNOPSIS\u001b[0m\n",
      "          aws s3 <Command> [<Arg> ...]\n",
      "\n",
      "\u001b[1mOPTIONS\u001b[0m\n",
      "       \u001b[4mNone\u001b[0m\n",
      "\n",
      "\u001b[1mAVAILABLE COMMANDS\u001b[0m\n",
      "       o cp\n",
      "\n",
      "       o ls\n",
      "\n",
      "       o mb\n",
      "\n",
      "       o mv\n",
      "\n",
      "       o presign\n",
      "\n",
      "       o rb\n",
      "\n",
      "       o rm\n",
      "\n",
      "       o sync\n",
      "\n",
      "       o website\n",
      "\n",
      "\n",
      "\n",
      "                                                                          S3()\n"
     ]
    }
   ],
   "source": [
    "!aws s3 help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see after running the above cell a list of commands that are available for working with S3 using the command line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run the command `mb` below to make a new bucket. As bucket names must be globally unique, you may need to modify the name slightly, for example by adding your name to the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make_bucket: susannaspoonersexamplebucket\n"
     ]
    }
   ],
   "source": [
    " !aws s3 mb s3://susannaspoonersexamplebucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run the `aws s3 ls` command to list buckets in your account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-17 14:52:29 susanna-first-bucket-for-qtm350\n",
      "2022-10-24 14:47:11 susannaspoonersexamplebucket\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to add an image to this bucket. There are many ways to do that. We will continue using the aws cli in order to accomplish this.\n",
    "\n",
    "First, using the JupyterLab file viewer on the left, click the up arrow symbol to upload a file to your Sagemaker instance. Upload either a .jpg or a .png. For example, I uploaded my profile picture named `jeremyjacobson.png`. Now move this file to your bucket using the `aws s3 mv` command. It works just like the `mv` command in Linux. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "move: ../../Screen-Shot.png to s3://susannaspoonersexamplebucket/Screen-Shot.png\n"
     ]
    }
   ],
   "source": [
    "!aws s3 mv ~/SageMaker/qtm350/Screen-Shot.png s3://susannaspoonersexamplebucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having run the cell above, the file should no longer appear in the JupyterLab file viewer. Let's check what is in the bucket we made now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-24 14:48:47      15032 Screen-Shot.png\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls susannaspoonersexamplebucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, we see that the image is in the bucket. Let's move on to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Detect labels in an image\n",
    "This example displays the JSON output from the `detect-labels` call to  the Rekognition API. You will need to modify it by replacing Bucket with your bucket's name and replace Name with your file's name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Labels\": [\n",
      "        {\n",
      "            \"Name\": \"Number\",\n",
      "            \"Confidence\": 99.99539947509766,\n",
      "            \"Instances\": [],\n",
      "            \"Parents\": [\n",
      "                {\n",
      "                    \"Name\": \"Symbol\"\n",
      "                },\n",
      "                {\n",
      "                    \"Name\": \"Text\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"Name\": \"Text\",\n",
      "            \"Confidence\": 99.99539947509766,\n",
      "            \"Instances\": [],\n",
      "            \"Parents\": []\n",
      "        },\n",
      "        {\n",
      "            \"Name\": \"Symbol\",\n",
      "            \"Confidence\": 99.99539947509766,\n",
      "            \"Instances\": [],\n",
      "            \"Parents\": []\n",
      "        },\n",
      "        {\n",
      "            \"Name\": \"Word\",\n",
      "            \"Confidence\": 88.84640502929688,\n",
      "            \"Instances\": [],\n",
      "            \"Parents\": []\n",
      "        },\n",
      "        {\n",
      "            \"Name\": \"Alphabet\",\n",
      "            \"Confidence\": 60.56959915161133,\n",
      "            \"Instances\": [],\n",
      "            \"Parents\": [\n",
      "                {\n",
      "                    \"Name\": \"Text\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"Name\": \"Logo\",\n",
      "            \"Confidence\": 58.85789489746094,\n",
      "            \"Instances\": [],\n",
      "            \"Parents\": [\n",
      "                {\n",
      "                    \"Name\": \"Symbol\"\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"Name\": \"Trademark\",\n",
      "            \"Confidence\": 58.85789489746094,\n",
      "            \"Instances\": [],\n",
      "            \"Parents\": [\n",
      "                {\n",
      "                    \"Name\": \"Symbol\"\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"LabelModelVersion\": \"2.0\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!aws rekognition detect-labels --image '{\"S3Object\":{\"Bucket\":\"susannaspoonersexamplebucket\", \"Name\":\"Screen-Shot.png\"}}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step could be to use a command line tool like `jq` to extract from this JSON the information we are most interested in and use that to create a new dataset as we did in earlier notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Python SDK\n",
    "We start by importing the package which containts the code for the Python SDK, `boto3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "#PDX-License-Identifier: MIT-0 (For details, see https://github.com/awsdocs/amazon-rekognition-developer-guide/blob/master/LICENSE-SAMPLECODE.)\n",
    "\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create an instance `client` of the client object in the `boto3` package for `rekognition`. It will allow use to communicate and make requests to the Rekognition service using Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "client=boto3.client('rekognition')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using the client, we use the dot notation to access one of its methods, `detect_labels`. This example displays the labels that were detected in the input image like we did previously using the CLI. Again, replace the values of bucket and photo with the names of the Amazon S3 bucket and image that you used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidS3ObjectException",
     "evalue": "An error occurred (InvalidS3ObjectException) when calling the DetectLabels operation: Unable to get object metadata from S3. Check object key, region and/or access permissions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidS3ObjectException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10959/1346064747.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'S3Object'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Bucket'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"susannaspoonersexamplebucket\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"Screen-shot.png\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaxLabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    394\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidS3ObjectException\u001b[0m: An error occurred (InvalidS3ObjectException) when calling the DetectLabels operation: Unable to get object metadata from S3. Check object key, region and/or access permissions."
     ]
    }
   ],
   "source": [
    "response = client.detect_labels(Image={'S3Object':{'Bucket':\"susannaspoonersexamplebucket\",'Name':\"Screen-shot.png\"}}, MaxLabels=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's investigate what we have obtained as a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that it is a Python dictionary. Let's see what are the keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the values for the `Labels` key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response['LabelModelVersion']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see it is the same data as obtained before. Now, using Python and Pandas we could extract the data we want from this request and use it to create a new dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting faces in an image\n",
    "Here is another example. See the [documentation](https://docs.aws.amazon.com/rekognition/latest/dg/faces-detect-images.html) for details on this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws rekognition detect-faces \\\n",
    "--image '{\"S3Object\":{\"Bucket\":\"susannaspoonersexamplebucket\",\"Name\":\"Screen-Shot.png\"}}' \\\n",
    "--attributes \"ALL\" \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is much more that can be done, such as detecting text and reading it. See the [linked documentation](https://docs.aws.amazon.com/rekognition/latest/dg/text-detecting-text-procedure.html) for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other ML Services\n",
    "There are countless new models that are in use today and not offered by AWS as a core ML service. To use them in Sagemaker we can use any of the opensource frameworks for ML with Python such as Tensorflow or PyTorch. The latter we will focus on in the final project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
